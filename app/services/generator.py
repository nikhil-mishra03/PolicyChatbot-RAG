# accepts relevant chunks from the user
# returns a response generated by the LLM based on the context from the vector storage
from typing import Any
from app.core.config import Settings
from openai import OpenAI
from openai import OpenAIError as openai_error
from app.core.logger_config import get_logger

class GeneratorService:
    def __init__(self, settings: Settings):
        self.settings = settings
        self.logger = get_logger(__class__.__name__)

    def _get_openai_client(self) -> OpenAI:
        return OpenAI(api_key=self.settings.openai_api_key)


    def generate_answer(self, *, question: str, retrieval_results: dict[str, Any]):
        docs = retrieval_results.get('documents', [[]])[0]
        metas = retrieval_results.get('metadatas', [[]])[0]
        distances = retrieval_results.get('distances', [[]])[0]
        if not docs or not metas:
            raise RuntimeError("No relevant documents found for the given question.")
        context_blocks = [
            f"source {i+1} ({meta.get('s3_key', 'unknown')} | chunk {meta['chunk_index']}): {doc} (distance: {distances[i]:.4f})"
            for i, (doc, meta) in enumerate(zip(docs, metas))
        ]

        context = "\n\n".join(context_blocks)
        prompt = (
            "You are a compliance assistant. Answer the question strictly using the provided policy context.\n"
            "If the answer is not in the context, say you do not know.\n\n"
            f"Context:\n{context}\n\nQuestion: {question}\nAnswer:"
        )
        try:
            client = self._get_openai_client()
            response = client.chat.completions.create(
                model = self.settings.openai_model_name,
                messages=[
                    {"role": "system", "content": "You are a helpful policy assistant..."},
                    {"role": "user", "content": prompt},
                ],
                temperature=1.0,
            )
        except openai_error as e:
            self.logger.error(f"OpenAI API error: {e}")
            raise RuntimeError(f"OpenAI API error: {e}")
        
        self.logger.info("Generated response from OpenAI successfully.")
        answer = response.choices[0].message.content.strip()
        sources = [
            {
                # "text": doc,
                "chunk_id": meta.get("chunk_index", "unknown"),
                "tenant_id": meta.get("tenant_id", "unknown"),
                "s3_key": meta.get("s3_key", "unknown"),
                "distance": distances[i]
            }
            for i , (meta, doc) in enumerate( zip(metas, docs) )
        ]

        return {
            "answer": answer,
            "sources": sources
        }

        


    
        


